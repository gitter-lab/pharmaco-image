{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest with Fingerprint\n",
    "\n",
    "In this baseline model, we want to use compound's fingerprint to predict the outcome of assay. This is a single task, and the prediction performance is measured by the test set with cross-validation.\n",
    "\n",
    "The fingerprint is extracted from all compounds with length `1024`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from json import load, dump\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9404, 141)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the output matrix\n",
    "output_matrix_npz = np.load(\"./resource/output_matrix.npz\")\n",
    "compound_inchi = output_matrix_npz[\"compound_inchi\"]\n",
    "compound_broad_id = output_matrix_npz[\"compound_broad_id\"]\n",
    "output_matrix = output_matrix_npz[\"output_matrix\"]\n",
    "output_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fingerprint\n",
    "fingerprint = np.load(\"./resource/fp_features.npz\")\n",
    "\n",
    "# Build the feature array\n",
    "fp_feature = np.zeros((len(compound_broad_id), fingerprint[\"features\"].shape[1]))\n",
    "\n",
    "# Choose selected compounds and arrange them by the output matrix order\n",
    "fp_index = dict(zip(fingerprint[\"names\"].astype(str), range(len(fingerprint[\"names\"]))))\n",
    "\n",
    "for b in range(len(compound_broad_id)):\n",
    "    bid = compound_broad_id[b]\n",
    "    fp_feature[b, :] = fingerprint[\"features\"][fp_index[bid], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took one hour to create this $9404 \\times 1024$ feature matrix with finger print on condor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9404, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_feature = np.load(\"./resource/extracted_fp_feature.npz\")[\"feature\"]\n",
    "fp_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the PriA-SSB study, some good parameters for a random forests are selected with a different assay dataset. We expect the best parameters (`RF_h`) to perform well in this dataset.\n",
    "\n",
    "For each assay, we only train and predict on compounds that give non-NA results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://user-images.githubusercontent.com/3532898/46812713-e8a93280-cd3a-11e8-949a-3469236a3943.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_on_assay(assay_array, rf, kfold=5, n_jobs=4):\n",
    "    \"\"\"\n",
    "    Train and measure a random forest model in a cross validation fasshion.\n",
    "    The model is only trained on compounds which give non-NA results.\n",
    "    \"\"\"\n",
    "    # Filter out NA from the assay_array\n",
    "    y_index = [False if a == -1 else True for a in assay_array ]\n",
    "    y = assay_array[y_index]\n",
    "    x = fp_feature[y_index, :]\n",
    "    \n",
    "    if Counter(y)[1] < kfold:\n",
    "        print(\"Warning: the number of total postives is less than kfold\")\n",
    "        \n",
    "    # One-hot encode y array\n",
    "    #y = np.vstack([[1, 0] if i == 1 else [0, 1] for i in y])\n",
    "    \n",
    "    # Build the cross validation scheme\n",
    "    # Since some assays have extremely small number of positives,\n",
    "    # I will use StratifiedKFold to preserve the proportion of positive in test set\n",
    "    \n",
    "    my_kfold_gen = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    scoring = [\"f1\", \"accuracy\", \"precision\", \"recall\", \"average_precision\", \"roc_auc\"]\n",
    "    cv = cross_validate(rf, x, y, scoring=scoring, cv=my_kfold_gen, n_jobs=n_jobs,\n",
    "                        return_train_score=False)\n",
    "    \n",
    "    cv[\"total_count\"] = Counter(y)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=8000, max_features=\"log2\",\n",
    "                                       min_samples_leaf=1, class_weight=\"balanced\")\n",
    "\n",
    "for i in range(output_matrix.shape[1]):\n",
    "    print(i)\n",
    "    results[i] = train_rf_on_assay(output_matrix[:,i], rf_classifier, kfold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a stratified 5-fold cross validation for each assay and record metrics on 5 test sets.\n",
    "\n",
    "It took 2 hour to train these 141 single tasks. We can visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.load(\"./resource/results.npz\")['results'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_score(results):\n",
    "    \"\"\"\n",
    "    Aggregate each score over 5 test sets.\n",
    "    \"\"\"\n",
    "    mean_df = {\n",
    "        \"f1\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"average_precision\": [],\n",
    "        \"roc_auc\": [],\n",
    "        \"precision\": [],\n",
    "        \"recall\": [],\n",
    "        \"pos_num\": [],\n",
    "        \"neg_num\": []\n",
    "    }\n",
    "    \n",
    "    for k, r in results.items():\n",
    "        mean_df[\"f1\"].append(np.mean(r[\"test_f1\"]))\n",
    "        mean_df[\"accuracy\"].append(np.mean(r[\"test_accuracy\"]))\n",
    "        mean_df[\"average_precision\"].append(np.mean(r[\"test_average_precision\"]))\n",
    "        mean_df[\"roc_auc\"].append(np.mean(r[\"test_roc_auc\"]))\n",
    "        mean_df[\"precision\"].append(np.mean(r[\"test_precision\"]))\n",
    "        mean_df[\"recall\"].append(np.mean(r[\"test_recall\"]))\n",
    "        mean_df[\"pos_num\"].append(r[\"total_count\"][1])\n",
    "        mean_df[\"neg_num\"].append(r[\"total_count\"][0])\n",
    "    \n",
    "    return pd.DataFrame(mean_df)\n",
    "\n",
    "mean_df = get_mean_score(results)\n",
    "mean_df.to_csv(\"./mean_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>pos_num</th>\n",
       "      <th>neg_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.249031</td>\n",
       "      <td>0.753840</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>17</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759369</td>\n",
       "      <td>0.682051</td>\n",
       "      <td>0.781926</td>\n",
       "      <td>0.746656</td>\n",
       "      <td>0.676644</td>\n",
       "      <td>0.867821</td>\n",
       "      <td>196</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183729</td>\n",
       "      <td>0.781891</td>\n",
       "      <td>0.520559</td>\n",
       "      <td>0.776232</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>74</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.828373</td>\n",
       "      <td>0.400695</td>\n",
       "      <td>0.698030</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>210</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.930673</td>\n",
       "      <td>0.168273</td>\n",
       "      <td>0.654066</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>128</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.660623</td>\n",
       "      <td>0.701898</td>\n",
       "      <td>0.792594</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.704681</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>180</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992296</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>0.657967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>3221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.250102</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>0.509820</td>\n",
       "      <td>0.675496</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>215</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.886010</td>\n",
       "      <td>0.264240</td>\n",
       "      <td>0.685354</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>396</td>\n",
       "      <td>3078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  accuracy  average_precision   roc_auc  precision    recall  \\\n",
       "0  0.080000  0.989659           0.249031  0.753840   0.200000  0.050000   \n",
       "1  0.759369  0.682051           0.781926  0.746656   0.676644  0.867821   \n",
       "2  0.183729  0.781891           0.520559  0.776232   0.533333  0.121905   \n",
       "3  0.158615  0.828373           0.400695  0.698030   0.805556  0.090476   \n",
       "4  0.030199  0.930673           0.168273  0.654066   0.400000  0.015692   \n",
       "5  0.660623  0.701898           0.792594  0.774347   0.704681  0.622222   \n",
       "6  0.000000  0.992296           0.026350  0.657967   0.000000  0.000000   \n",
       "7  0.580000  0.470000           0.777778  0.633333   0.500000  0.733333   \n",
       "8  0.250102  0.678020           0.509820  0.675496   0.553435  0.162791   \n",
       "9  0.019755  0.886010           0.264240  0.685354   0.566667  0.010095   \n",
       "\n",
       "   pos_num  neg_num  \n",
       "0       17     1530  \n",
       "1      196      143  \n",
       "2       74      256  \n",
       "3      210      932  \n",
       "4      128     1747  \n",
       "5      180      206  \n",
       "6       24     3221  \n",
       "7       11       10  \n",
       "8      215      431  \n",
       "9      396     3078  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across 141 assays, the average f1=10.03%, accuracy=91.96%, ap=30.35%, auc=72.19%, precision=27.76%, recall=7.83%.\n"
     ]
    }
   ],
   "source": [
    "print((\"Across 141 assays, the average f1={:.2f}%, accuracy={:.2f}%, ap={:.2f}%, auc={:.2f}%, \" + \\\n",
    "       \"precision={:.2f}%, recall={:.2f}%.\").format(\n",
    "    np.mean(mean_df[\"f1\"]) * 100,\n",
    "    np.mean(mean_df[\"accuracy\"]) * 100,\n",
    "    np.mean(mean_df[\"average_precision\"]) * 100,\n",
    "    np.mean(mean_df[\"roc_auc\"]) * 100,\n",
    "    np.mean(mean_df[\"precision\"]) * 100,\n",
    "    np.mean(mean_df[\"recall\"]) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![random_forest_plot_1.png](./plots/random_forest_plot_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Comments\n",
    "\n",
    "- Accuracies are pretty high except some outliers with few assays. It is due to the skewness of positive samples.\n",
    "- This baseline model performs poorly based on metrics `F1`, `AP`, `Precision`, `Recall`.\n",
    "- However, this model has high `AUC`, which is the main metric used in the ICCR paper.\n",
    "- Using `AUC`, finterprint baseline gives a similar result as ICCR paper's advanced model (attached below).\n",
    "- `AP` has a very large variance. Low sample size (both pos and neg) tends to give high `AP` values.\n",
    "\n",
    "![](https://i.imgur.com/Z790iMB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
